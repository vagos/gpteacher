{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9563a30e-a115-4e71-84ee-10d7034c19a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ecad70ee-1241-45dc-a160-6ab2407a05e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vagozino/.conda/envs/llm/lib/python3.11/site-packages/huggingface_hub/utils/_deprecation.py:127: FutureWarning: '__init__' (from 'huggingface_hub.inference_api') is deprecated and will be removed from version '0.19.0'. `InferenceApi` client is deprecated in favor of the more feature-complete `InferenceClient`. Check out this guide to learn how to convert your script to use it: https://huggingface.co/docs/huggingface_hub/guides/inference#legacy-inferenceapi-client.\n",
      "  warnings.warn(warning_message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import langchain as lc\n",
    "from langchain.llms import HuggingFaceHub\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "llm = HuggingFaceHub(\n",
    "    repo_id=\"google/flan-t5-xxl\", \n",
    "    model_kwargs={\"temperature\": 1.0, \"max_length\":4096},\n",
    ")\n",
    "\n",
    "# llm = OpenAI()\n",
    "# llm = ChatOpenAI(model=\"gpt-3.5-turbo-0301\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "28c27c23-6970-4e90-8226-bcebf6fe78e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.globals import set_debug\n",
    "from langchain.globals import set_verbose\n",
    "\n",
    "DEBUG = False\n",
    "\n",
    "if DEBUG:\n",
    "    set_verbose(True)\n",
    "    set_debug(True)\n",
    "else:\n",
    "    set_verbose(False)\n",
    "    set_debug(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea879d86-07af-4e54-ac3b-3cf8d6a37fc4",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "63daa80a-a0e1-42ba-bc4d-2e175eece67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "from pathlib import Path\n",
    "from typing import Any, List\n",
    "\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.document_loaders import SRTLoader\n",
    "from langchain.document_loaders.base import BaseLoader\n",
    "\n",
    "\n",
    "class LectureLoader(BaseLoader):\n",
    "    def __init__(self, \n",
    "                 lecture_file: str,\n",
    "                 add_lecture_info: bool = False\n",
    "                ):\n",
    "        self.add_lecture_info = add_lecture_info\n",
    "        self.lecture_file = lecture_file\n",
    "\n",
    "    @classmethod\n",
    "    def from_folder(cls, folder_name: str, **kwargs: Any) -> 'LectureLoader':\n",
    "        return cls(folder_name, kwargs)\n",
    "\n",
    "    def load(self) -> List[Document]:\n",
    "        documents = []\n",
    "        \n",
    "        for file_name in Path(self.lecture_file).rglob('*'):\n",
    "            \n",
    "            file_path = Path(file_name)\n",
    "            if not file_path.is_file(): continue\n",
    "                \n",
    "            with open(file_name, \"r\") as f:\n",
    "\n",
    "                metadata = {}\n",
    "                \n",
    "                # Load the transcript data\n",
    "                if file_name.suffix == \".srt\":\n",
    "                # or file_name.suffix == \".sbv\" \\\n",
    "                # or file_name.suffix == \".vtt\" \\\n",
    "                # or file_name.suffix == \".txt\":\n",
    "\n",
    "                    srt_loader = SRTLoader(file_name)\n",
    "                        \n",
    "                    if self.add_lecture_info:\n",
    "                        metadata[\"lecture_name\"] = file_path.parent.name\n",
    "                        metadata[\"source\"] = file_path.stem\n",
    "                        metadata[\"type\"] = \"transcript\"\n",
    "\n",
    "                    for doc in srt_loader.load():\n",
    "                        doc.metadata.update(metadata)\n",
    "                        documents.append(doc)\n",
    "\n",
    "        return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c38604d-90f7-4cb0-bdd4-8550e48d5a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.vectorstores.base import VectorStore\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.schema.embeddings import Embeddings\n",
    "\n",
    "from typing import Type, Iterable, Optional, List\n",
    "\n",
    "\n",
    "class LectureIndex(FAISS):\n",
    "    \"\"\"Wrapper around the FAISS VectorStore\"\"\"\n",
    "\n",
    "    @classmethod\n",
    "    def from_documents(cls, documents: List[Document], embedding: Embeddings):\n",
    "        text_splitter = RecursiveCharacterTextSplitter(chunk_size = 500, chunk_overlap = 100)\n",
    "        docs_split = text_splitter.split_documents(documents)\n",
    "        return FAISS.from_documents(docs_split, embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d7edbf16-a528-4216-9e25-b0a01c36b5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2')\n",
    "\n",
    "lecture_loader = LectureLoader.from_folder(\"./data\", add_lecture_info=True)\n",
    "lecture_docs = lecture_loader.load()\n",
    "\n",
    "lecture_index = LectureIndex.from_documents(lecture_docs, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8a31e763-5e7f-4e6f-b920-ef99b47ed94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = lecture_index.similarity_search(\"Can you tell me what the professor in lecture1 says right after 5 minutes?\")\n",
    "\n",
    "for doc in results:\n",
    "    pass\n",
    "    # print(\"- \", doc.page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ac2114-5f2a-46b4-9da4-77680f4d021f",
   "metadata": {},
   "source": [
    "## Simple Question Answering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f3666887-511e-4da2-84b8-67feafa244fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is one person in here for whom the reading of Plato's Republic will be the most\n"
     ]
    }
   ],
   "source": [
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain import hub\n",
    "\n",
    "# Retrieval Augmented Generation (RAG)\n",
    "retriever = lecture_index.as_retriever(k=10)\n",
    "rag_prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "rag_chain = {\"context\": retriever, \"question\": RunnablePassthrough()} | rag_prompt | llm\n",
    "\n",
    "query = \"Any good students?\"\n",
    "answer = rag_chain.invoke(query)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca3e0f8-6424-4204-a3a9-7bd8945dcdee",
   "metadata": {},
   "source": [
    "## Question Answering using Embedding Index and SQL Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "27196b3e-158d-4c7d-b329-ba0a11d50251",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pysrt\n",
    "\n",
    "class SubtitleIndex:\n",
    "    \"\"\"\n",
    "    Can load timestamps from an .srt file and retrieve subtitles between a given time range.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.connection = sqlite3.connect('subtitles.db')\n",
    "        self.cursor = self.connection.cursor()\n",
    "\n",
    "        # Create the table\n",
    "        self.cursor.execute('''\n",
    "        CREATE TABLE IF NOT EXISTS subtitles (\n",
    "            video_id TEXT,\n",
    "            start_time TEXT,\n",
    "            end_time TEXT,\n",
    "            subtitle_text TEXT,\n",
    "            UNIQUE(video_id, start_time, end_time, subtitle_text)\n",
    "            )\n",
    "        ''')\n",
    "    \n",
    "    def get_subtitles(self, time_start: str, time_end: str, video_id='%') -> List[str]:\n",
    "        self.cursor.execute('''\n",
    "                SELECT * FROM subtitles\n",
    "                WHERE start_time BETWEEN ? AND ?\n",
    "                AND video_id LIKE ?\n",
    "            ''', (time_start, time_end, video_id))\n",
    "\n",
    "        rows = self.cursor.fetchall()\n",
    "\n",
    "        return rows\n",
    "\n",
    "    def add_subtitle_file(self, subtitle_filename, video_id):\n",
    "        def to_timestamp(srt_time):\n",
    "            # Format the time to a string as HH:MM:SS,SSS\n",
    "            return '{:02}:{:02}:{:02},{:03}'.format(srt_time.hours,\n",
    "                                                    srt_time.minutes,\n",
    "                                                    srt_time.seconds,\n",
    "                                                    srt_time.milliseconds)\n",
    "\n",
    "        subs = pysrt.open(subtitle_filename)\n",
    "\n",
    "        for sub in subs:\n",
    "            start_time = to_timestamp(sub.start)\n",
    "            end_time = to_timestamp(sub.end)\n",
    "            subtitle_text = sub.text.replace('\\n', ' ')  # Remove newline characters\n",
    "\n",
    "            try:\n",
    "                self.cursor.execute('''\n",
    "                    INSERT INTO subtitles (video_id, start_time, end_time, subtitle_text)\n",
    "                    VALUES (?, ?, ?, ?)\n",
    "                    ''', (lecture_id, start_time, end_time, subtitle_text))\n",
    "\n",
    "            except sqlite3.IntegrityError:\n",
    "                print(\"Duplicate subtitle: \", sub)\n",
    "                \n",
    "        self.connection.commit()\n",
    "\n",
    "    def __del__(self):\n",
    "        self.connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "41ddecf0-25a4-494e-9168-6c1048de3360",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the Database\n",
    "\n",
    "sub_file = \"./data/lecture1/4. Philosophers and Kings： Plato's Republic, I-II [nVQKbQVc2_w].en.srt\"\n",
    "lecture_id = 'lecture1'\n",
    "\n",
    "subtitle_index = SubtitleIndex()\n",
    "subtitle_index.add_subtitle_file(sub_file, lecture_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9183d216-ce67-493d-ba07-b657feb1ec10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Answer: In the lecture1 between minute 0 and 1, Professor Steven Smith mentioned that there is one person in the room for whom the reading of Plato's Republic will be the most important intellectual experience they will have at Yale. He asked the person to remember this and email him four years from now to let him know who it is.\n"
     ]
    }
   ],
   "source": [
    "# subtitle_index.get_subtitles('00:00:00.000', '00:01:01.000', 'lecture1')\n",
    "\n",
    "from langchain.utilities import SQLDatabase\n",
    "from langchain.chains import create_sql_query_chain\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chains.router import MultiRetrievalQAChain\n",
    "\n",
    "subtitle_db = SQLDatabase.from_uri(\"sqlite:///subtitles.db\")\n",
    "query_chain = create_sql_query_chain(llm, subtitle_db, k=200)\n",
    "\n",
    "system_message = \"\"\"Use the information from the below sources to answer any questions.\n",
    "\n",
    "Source 1: Relevant timestamped snippets from the lecture. Use if the questions mentions\n",
    "a specific part of the lecture.\n",
    "<source1>\n",
    "{source1}\n",
    "</source1>\n",
    "\n",
    "Source 2: Content from the lecture. Use if relevant to the question.\n",
    "<source2>\n",
    "{source2}\n",
    "</source2>\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [(\"system\", system_message), (\"human\", \"{question}\")]\n",
    ")\n",
    "\n",
    "\n",
    "full_chain = (\n",
    "    {\n",
    "        \"source1\": {\"question\": lambda x: x[\"question\"]} | query_chain | subtitle_db.run,\n",
    "        \"source2\": (lambda x: x[\"question\"]) | retriever,\n",
    "        \"question\": lambda x: x[\"question\"],\n",
    "    }\n",
    "    | prompt\n",
    "    | llm\n",
    ")\n",
    "\n",
    "response = full_chain.invoke({\"question\": \"Can you explain the content between minute 0 and 1?\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e93027-a2ee-4f48-9951-094c3ebd4878",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experimenting with MultiRetrievalQAChain (currently unable to retrieve content from SQL Database)\n",
    "# This code DOES NOT work\n",
    "retriever_infos = [\n",
    "    {\n",
    "        \"name\": \"Lecture Timestamps\",\n",
    "        \"description\": \"Good for answering questions that refer to specific time points in the lecture.\",\n",
    "        \"retriever\": query_chain\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Lecture Content\",\n",
    "        \"description\": \"Good for answering questions about the lecture generally\",\n",
    "        \"retriever\": retriever\n",
    "    }\n",
    "]\n",
    "\n",
    "# Disabled the below snippet\n",
    "if False:\n",
    "    chain = MultiRetrievalQAChain.from_retrievers(llm, retriever_infos, verbose=True)\n",
    "    print(chain.run(\"Can you tell me what the professor in lecture1 says right after 5 minutes?\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "llm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
